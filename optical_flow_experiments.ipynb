{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical flow experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal pixel displacement\n",
    "\n",
    "\n",
    "How much does a 3D point move horizontally relative to the concentric mosaic camera?\n",
    "\n",
    "![Overview](jupyter_files/overview.png)\n",
    "\n",
    " $p(\\alpha)=(d+r) \\begin{bmatrix}\\cos(\\alpha)\\\\\\sin(\\alpha)\\\\h\\end{bmatrix}$: 3D point\n",
    " \n",
    " $d$: distance of point to capture circle\n",
    " \n",
    " $r$: capture circle radius\n",
    " \n",
    " $h$: height of 3D point (perpendicular to drawing plane)\n",
    " \n",
    " $\\alpha$: point's global azimuth angle relative to camera's principal axis\n",
    " \n",
    " $\\beta$: point's azimuth in camera coordinate frame\n",
    " \n",
    " $c = (d+r) \\sin(\\alpha)$\n",
    " \n",
    " $e = (d+r) \\cos(\\alpha)$\n",
    " \n",
    " $\\tan(\\beta) = \\frac{c}{e-r} = \\frac{(d+r)\\sin(\\alpha)}{(d+r)\\cos(\\alpha)-r}$\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In equirectangular projection\n",
    "\n",
    "$$\\beta = \\arctan\\left(\\frac{(d+r)\\sin(\\alpha)}{(d+r)\\cos(\\alpha)-r}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary r and d(>r)\n",
    "d = 3.0\n",
    "r = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('text', usetex = True)\n",
    "\n",
    "ùõº = np.linspace(-np.pi, np.pi, 100)\n",
    "\n",
    "ùõΩ = np.arctan2((d+r)*np.sin(ùõº), (d+r)*np.cos(ùõº)-r)\n",
    "\n",
    "plt.plot(ùõº, ùõΩ)\n",
    "ticks = np.r_[-180:181:90]\n",
    "plt.xticks(ticks*np.pi/180, [str(t)+'¬∞' for t in ticks])\n",
    "plt.yticks(ticks*np.pi/180, [str(t)+'¬∞' for t in ticks])\n",
    "plt.xlabel('$\\\\alpha$')\n",
    "plt.ylabel('$\\\\beta$')\n",
    "plt.plot(ùõº, ùõº, 'r:')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In pinhole projection\n",
    "\n",
    "$$x = f \\frac{c}{e-r} = f \\tan(\\beta) = f \\frac{(d+r)\\sin(\\alpha)}{(d+r)\\cos(\\alpha)-r}, \\quad \\text{$f$: focal length}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary FOV between, for example, 20¬∞ and 180¬∞\n",
    "horizontal_fov = 60 /180*np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ùõº = np.arctan2( d * np.tan(horizontal_fov/2), d + r)\n",
    "ùõº = np.linspace(-max_ùõº/2, max_ùõº/2, 100)\n",
    "x = (d+r)*np.sin(ùõº)/((d+r)*np.cos(ùõº)-r)\n",
    "plt.plot(ùõº, x)\n",
    "ticks = np.linspace(-max_Œ±/2, max_Œ±/2, 5)\n",
    "plt.xticks(ticks, [f'{t*180/np.pi:.1f}¬∞' for t in ticks])\n",
    "plt.yticks(ticks)\n",
    "plt.xlabel('$\\\\alpha$')\n",
    "plt.ylabel('$x/f$')\n",
    "plt.plot([-max_Œ±/2, max_Œ±/2], x[[0,-1]], 'r:')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In both cases, pinhole and equirecatangular, the horizontal pixel displacement of a uniformly moving 3D point is *not* perfectly linear. Especially for points close to the camera and for wide fields of view, the mapping between relative angular point-camera position and horizontal displacement in the image has a slight S-shape.\n",
    "\n",
    "For small changes in ùõº, however, the local behaviour can be approximated with a linear function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optical flow as measure for relative angular position\n",
    "\n",
    "Using any dense optical flow method from OpenCV, test if occlusions and other inconsistencies can be detected by chaining the optical flows $\\texttt{frame}_A \\rightarrow \\texttt{frame}_B$ and $\\texttt{frame}_B\\rightarrow \\texttt{frame}_A$ and testing for small deviations.\n",
    "\n",
    "Also check if the ratio of horizontal optical flow magnitudes reliably represents the angular position of $\\texttt{frame}_0$ halfway between $\\texttt{frame}_{N-1}$ and $\\texttt{frame}_{N}$, i.e. if\n",
    "\n",
    "$$\n",
    " \\frac{\\left|f^x_{0,N-1}(x,y)\\right|}{\\left|f^x_{0,N}(x,y)\\right|} =  \\frac{\\delta}{\\Delta\\alpha-\\delta}\n",
    "$$\n",
    "or\n",
    "$$\n",
    " \\frac{\\left|f^x_{0,N-1}(x,y)\\right|}{\\left|f^x_{0,N}(x,y)\\right|+\\left|f^x_{0,N-1}(x,y)\\right|} =  \\frac{\\delta}{\\Delta\\alpha}\n",
    "$$\n",
    "\n",
    "![Loop closure](jupyter_files/loop_closure.png)\n",
    "\n",
    "For reference, in Numpy notation, OpenCV defines the flow $f_{A,B}$ between $\\texttt{frame}_A$ and $\\texttt{frame}_B$ by\n",
    "$$\\texttt{frame}_A [y,x,:]  \\sim \\texttt{frame}_B \\left[ y + f_{A,B}[y,x,1],  x + f_{A,B}[y,x,0], :\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 1\n",
    "%aimport video_loop_finder\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from video_loop_finder import VideoLoopFinder\n",
    "\n",
    "\n",
    "flow_algo = cv2.optflow.createOptFlow_Farneback()\n",
    "\n",
    "start_frame_idx = 990\n",
    "closest_end_frame_idx = 2790\n",
    "video_loop_finder = VideoLoopFinder('/home/florians/Videos/VID_2019_09_26_14_02_58_20191015155545.mp4',\n",
    "                                    start_frame_idx=start_frame_idx,\n",
    "                                    resolution=256)\n",
    "\n",
    "# For testing, use frames 999(‚âôN-1), 1000(‚âô0), 1000+x(‚âôN) => expected outcome: Œîùõº=(1+x)ùõø\n",
    "x = 1\n",
    "frame_0 = video_loop_finder._seek(1000)\n",
    "frame_N = [video_loop_finder._seek(1000 + x), \n",
    "           video_loop_finder._seek(999)]\n",
    "\n",
    "# Opt. flow from frame N to 0 and its reverse\n",
    "flow_N = (flow_algo.calc(frame_N[0], frame_0, None), \n",
    "           flow_algo.calc(frame_0, frame_N[0], None))\n",
    "# Opt. flow from 0 to N-1 and its reverse\n",
    "flow_0 = (flow_algo.calc(frame_0, frame_N[1], None),\n",
    "          flow_algo.calc(frame_N[1], frame_0, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directional_colorbar(axes):\n",
    "    for angle in np.linspace(-np.pi,np.pi):\n",
    "        axes.bar(angle, 1, color=colors.hsv_to_rgb((angle/2/np.pi+0.5,1.0,1.0)))\n",
    "    axes.set_yticks([])\n",
    "    axes.set_xticklabels([f'{h}¬∞' for h in [*range(0,181, 45), *range(-135,0,45)]])\n",
    "    axes.set_position([0.55,0.4, 0.2,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sanity check: visualize flow\n",
    "\n",
    "from matplotlib import colors\n",
    "\n",
    "flow_to_plot = flow_0\n",
    "\n",
    "plt.set_cmap(plt.cm.jet)\n",
    "hue = np.arctan2(flow_to_plot[0][...,1], flow_to_plot[0][...,0]) / 2/np.pi + 0.5\n",
    "value = np.linalg.norm(flow_to_plot[0], axis=-1)\n",
    "rgb = colors.hsv_to_rgb(np.dstack((hue, np.ones_like(hue), 1-np.exp(-value))))\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_figwidth(15)\n",
    "fig.set_figheight(8)\n",
    "ax = fig.add_subplot(121), fig.add_subplot(122, polar=True)\n",
    "im = ax[0].imshow(rgb)\n",
    "im.format_cursor_data = lambda d: (f'dir: {(colors.rgb_to_hsv(d)[0]-0.5)*360:.0f}¬∞, '\n",
    "                                   f'mag: {colors.rgb_to_hsv(d)[2]:.3f}')\n",
    "directional_colorbar(ax[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "# Visualise filtering result\n",
    "\n",
    "# Vary threshold\n",
    "filter_threshold = 0.2\n",
    "\n",
    "from video_loop_finder import VideoLoopFinder\n",
    "\n",
    "filter_optical_flow = VideoLoopFinder.filter_optical_flow\n",
    "\n",
    "filtered_flow = filter_optical_flow(flow_to_plot[0], flow_to_plot[1], filter_threshold)\n",
    "\n",
    "hue = np.arctan2(filtered_flow[...,1], filtered_flow[...,0]) / 2/np.pi + 0.5\n",
    "value = np.linalg.norm(filtered_flow, axis=-1)\n",
    "rgb = colors.hsv_to_rgb(np.dstack((hue, np.ones_like(hue), 1-np.exp(-value))))\n",
    "rgb[np.any(filtered_flow.mask, -1),:] = np.nan\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_figwidth(15)\n",
    "fig.set_figheight(8)\n",
    "ax = fig.add_subplot(121), fig.add_subplot(122, polar=True)\n",
    "im = ax[0].imshow(rgb)\n",
    "im.format_cursor_data = lambda d: (f'dir: {(colors.rgb_to_hsv(d)[0]-0.5)*360:.0f}¬∞, '\n",
    "                                   f'mag: {colors.rgb_to_hsv(d)[2]:.3f}')\n",
    "directional_colorbar(ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "# %%pixie_debugger -b24\n",
    "\n",
    "filter_thresholds = np.logspace(-4,0)\n",
    "filter_optical_flow = VideoLoopFinder.filter_optical_flow\n",
    "\n",
    "output_ratios = []\n",
    "output_std = []\n",
    "for filter_threshold in filter_thresholds:\n",
    "    # Horizontal component of flow from 0 to N-1\n",
    "    xflow_0_to_end = np.abs(filter_optical_flow(flow_0[0], flow_0[1], filter_threshold)[...,0]).filled()\n",
    "    \n",
    "    # Horizontal component of flow from 0 to N\n",
    "    xflow_0_to_N = np.abs(filter_optical_flow(flow_N[1], flow_N[0], filter_threshold)[...,0]).filled()\n",
    "\n",
    "    xflow_sum = xflow_0_to_N + xflow_0_to_end\n",
    "    Œ¥_over_Œîùõº = np.nanmedian(xflow_0_to_end[xflow_sum != 0] / xflow_sum[xflow_sum != 0])\n",
    "    \n",
    "#     print(f'{filter_threshold:0.4f}', Œ¥_over_Œîùõº)\n",
    "    output_ratios.append(Œ¥_over_Œîùõº)\n",
    "    output_std.append(np.nanstd(xflow_0_to_end[xflow_sum != 0] / xflow_sum[xflow_sum != 0]) / 2)\n",
    "plt.errorbar(filter_thresholds, output_ratios, output_std, fmt='.-', ecolor='gray', elinewidth=.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "The outlier detection based on chaining optical flows in forward and backward direction appears to work.\n",
    "\n",
    "Determining the ratio of $\\delta$ to $\\Delta\\alpha$ from optical flow ratios works reliably, and appears to give stable results for outlier thresholds above 0.1 pixels."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
